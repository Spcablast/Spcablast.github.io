<!DOCTYPE html>
<html lang=zh>
<head>
  <meta charset="utf-8">
  
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, minimum-scale=1, user-scalable=no, minimal-ui">
  <meta name="renderer" content="webkit">
  <meta http-equiv="Cache-Control" content="no-transform" />
  <meta http-equiv="Cache-Control" content="no-siteapp" />
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  <meta name="format-detection" content="telephone=no,email=no,adress=no">
  <!-- Color theme for statusbar -->
  <meta name="theme-color" content="#000000" />
  <!-- 强制页面在当前窗口以独立页面显示,防止别人在框架里调用页面 -->
  <meta http-equiv="window-target" content="_top" />
  
  
  <title>在，机器学习啥玩意儿啊 | Hexo</title>
  <meta name="description" content="###深度学习（Deep Learning）    1、基于卷积运算的神经网络系统，即卷积神经网络(CNN)。    2、基于多层神经元的自编码神经网络，包括自编码( Auto encoder)以及近年来受到广泛关注的稀疏编码两类( Sparse Coding)。    3、以多层自编码神经网络的方式进行预训练，进而结合鉴别信息进一步优化神经网络权值的深度置信网络(DBN)。  好，所以这里我只关">
<meta property="og:type" content="article">
<meta property="og:title" content="在，机器学习啥玩意儿啊">
<meta property="og:url" content="http://spcablast.club/2021/12/02/%E5%9C%A8%EF%BC%8C%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%95%A5%E7%8E%A9%E6%84%8F%E5%84%BF%E5%95%8A/index.html">
<meta property="og:site_name" content="YP Blog">
<meta property="og:description" content="###深度学习（Deep Learning）    1、基于卷积运算的神经网络系统，即卷积神经网络(CNN)。    2、基于多层神经元的自编码神经网络，包括自编码( Auto encoder)以及近年来受到广泛关注的稀疏编码两类( Sparse Coding)。    3、以多层自编码神经网络的方式进行预训练，进而结合鉴别信息进一步优化神经网络权值的深度置信网络(DBN)。  好，所以这里我只关">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2021-12-02T01:30:35.845Z">
<meta property="article:modified_time" content="2021-12-02T11:12:23.735Z">
<meta property="article:author" content="YP">
<meta name="twitter:card" content="summary">
  <!-- Canonical links -->
  <link rel="canonical" href="http://spcablast.club/2021/12/02/%E5%9C%A8%EF%BC%8C%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%95%A5%E7%8E%A9%E6%84%8F%E5%84%BF%E5%95%8A/index.html">
  
    <link rel="alternate" href="/atom.xml" title="YP Blog" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png" type="image/x-icon">
  
  
<link rel="stylesheet" href="/css/style.css">

  
  
  
  
<meta name="generator" content="Hexo 4.2.0"></head>


<body class="main-center" itemscope itemtype="http://schema.org/WebPage">
  <header class="header" itemscope itemtype="http://schema.org/WPHeader">
  <div class="slimContent">
    <div class="navbar-header">
      
      
      <div class="profile-block text-center">
        <a id="avatar" href="https://github.com/Spcabalst" target="_blank">
          <img class="img-circle img-rotate" src="/images/avatar.jpg" width="200" height="200">
        </a>
        <h2 id="name" class="hidden-xs hidden-sm">SPCA</h2>
        <h3 id="title" class="hidden-xs hidden-sm hidden-md">Human</h3>
        <small id="location" class="text-muted hidden-xs hidden-sm"><i class="icon icon-map-marker"></i> Shenyang, China</small>
      </div>
      
      <div class="search" id="search-form-wrap">

    <form class="search-form sidebar-form">
        <div class="input-group">
            <input type="text" class="search-form-input form-control" placeholder="搜索" />
            <span class="input-group-btn">
                <button type="submit" class="search-form-submit btn btn-flat" onclick="return false;"><i class="icon icon-search"></i></button>
            </span>
        </div>
    </form>
    <div class="ins-search">
  <div class="ins-search-mask"></div>
  <div class="ins-search-container">
    <div class="ins-input-wrapper">
      <input type="text" class="ins-search-input" placeholder="想要查找什么..." x-webkit-speech />
      <button type="button" class="close ins-close ins-selectable" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button>
    </div>
    <div class="ins-section-wrapper">
      <div class="ins-section-container"></div>
    </div>
  </div>
</div>


</div>
      <button class="navbar-toggle collapsed" type="button" data-toggle="collapse" data-target="#main-navbar" aria-controls="main-navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
    </div>
    <nav id="main-navbar" class="collapse navbar-collapse" itemscope itemtype="http://schema.org/SiteNavigationElement" role="navigation">
      <ul class="nav navbar-nav main-nav ">
        
        
        <li class="menu-item menu-item-home">
          <a href="/.">
            
            <i class="icon icon-home-fill"></i>
            
            <span class="menu-title">首页</span>
          </a>
        </li>
        
        
        <li class="menu-item menu-item-archives">
          <a href="/archives">
            
            <i class="icon icon-archives-fill"></i>
            
            <span class="menu-title">归档</span>
          </a>
        </li>
        
        
        <li class="menu-item menu-item-categories">
          <a href="/categories">
            
            <i class="icon icon-folder"></i>
            
            <span class="menu-title">分类</span>
          </a>
        </li>
        
        
        <li class="menu-item menu-item-tags">
          <a href="/tags">
            
            <i class="icon icon-tags"></i>
            
            <span class="menu-title">标签</span>
          </a>
        </li>
        
        
        <li class="menu-item menu-item-repository">
          <a href="/repository">
            
            <i class="icon icon-project"></i>
            
            <span class="menu-title">项目</span>
          </a>
        </li>
        
        
        <li class="menu-item menu-item-books">
          <a href="/books">
            
            <i class="icon icon-book-fill"></i>
            
            <span class="menu-title">书单</span>
          </a>
        </li>
        
        
        <li class="menu-item menu-item-links">
          <a href="/links">
            
            <i class="icon icon-friendship"></i>
            
            <span class="menu-title">友链</span>
          </a>
        </li>
        
        
        <li class="menu-item menu-item-about">
          <a href="/about">
            
            <i class="icon icon-cup-fill"></i>
            
            <span class="menu-title">关于</span>
          </a>
        </li>
        
      </ul>
      
	
    <ul class="social-links">
    	
        <li><a href="https://github.com/Spcabalst" target="_blank" title="Github" data-toggle=tooltip data-placement=top><i class="icon icon-github"></i></a></li>
        
        <li><a href="/null" target="_blank" title="Weibo" data-toggle=tooltip data-placement=top><i class="icon icon-weibo"></i></a></li>
        
        <li><a href="/null" target="_blank" title="Rss" data-toggle=tooltip data-placement=top><i class="icon icon-rss"></i></a></li>
        
    </ul>

    </nav>
  </div>
</header>

  
    <aside class="sidebar" itemscope itemtype="http://schema.org/WPSideBar">
  <div class="slimContent">
    
      <div class="widget">
    <h3 class="widget-title">公告</h3>
    <div class="widget-body">
        <div id="board">
            <div class="content">
                <p>Know yourself!</p>
            </div>
        </div>
    </div>
</div>

    
      
  <div class="widget">
    <h3 class="widget-title">分类</h3>
    <div class="widget-body">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Dailycode/">Dailycode</a><span class="category-list-count">29</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/VSCode/">VSCode</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E4%B9%A6/">书</a><span class="category-list-count">2</span></li></ul>
    </div>
  </div>


    
      
  <div class="widget">
    <h3 class="widget-title">标签</h3>
    <div class="widget-body">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/ffmpeg%E5%91%BD%E4%BB%A4%E8%A1%8C%E6%93%8D%E4%BD%9C/" rel="tag">-ffmpeg命令行操作</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ORBSLAM2/" rel="tag">ORBSLAM2</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/SLAM/" rel="tag">SLAM</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/c/" rel="tag">c++</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/dfs-%E7%AE%97%E6%B3%95%E9%A2%98/" rel="tag">dfs - 算法题</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/vector%E6%93%8D%E4%BD%9C%E5%92%8C-%E7%AE%97%E6%B3%95%E9%A2%98/" rel="tag">vector操作和 - 算法题</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/" rel="tag">动态规划</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92-%E7%AE%97%E6%B3%95%E9%A2%98/" rel="tag">动态规划 - 算法题</a><span class="tag-list-count">8</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%8F%94%E6%9C%AC%E5%8D%8E/" rel="tag">叔本华</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%84%8F%E6%AC%B2/" rel="tag">意欲</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%8E%A8%E7%90%86/" rel="tag">推理</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/" rel="tag">操作系统</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%B1%87%E7%BC%96/" rel="tag">汇编</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%9F%AD%E7%AF%87%E5%B0%8F%E8%AF%B4/" rel="tag">短篇小说</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%AE%97%E6%B3%95%E9%A2%98/" rel="tag">算法题</a><span class="tag-list-count">18</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E8%87%AA%E7%94%B1/" rel="tag">自由</a><span class="tag-list-count">1</span></li></ul>
    </div>
  </div>


    
      
  <div class="widget">
    <h3 class="widget-title">标签云</h3>
    <div class="widget-body tagcloud">
      <a href="/tags/ffmpeg%E5%91%BD%E4%BB%A4%E8%A1%8C%E6%93%8D%E4%BD%9C/" style="font-size: 13px;">-ffmpeg命令行操作</a> <a href="/tags/ORBSLAM2/" style="font-size: 13px;">ORBSLAM2</a> <a href="/tags/SLAM/" style="font-size: 13px;">SLAM</a> <a href="/tags/c/" style="font-size: 13px;">c++</a> <a href="/tags/dfs-%E7%AE%97%E6%B3%95%E9%A2%98/" style="font-size: 13px;">dfs - 算法题</a> <a href="/tags/vector%E6%93%8D%E4%BD%9C%E5%92%8C-%E7%AE%97%E6%B3%95%E9%A2%98/" style="font-size: 13.33px;">vector操作和 - 算法题</a> <a href="/tags/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/" style="font-size: 13px;">动态规划</a> <a href="/tags/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92-%E7%AE%97%E6%B3%95%E9%A2%98/" style="font-size: 13.67px;">动态规划 - 算法题</a> <a href="/tags/%E5%8F%94%E6%9C%AC%E5%8D%8E/" style="font-size: 13px;">叔本华</a> <a href="/tags/%E6%84%8F%E6%AC%B2/" style="font-size: 13px;">意欲</a> <a href="/tags/%E6%8E%A8%E7%90%86/" style="font-size: 13px;">推理</a> <a href="/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/" style="font-size: 13px;">操作系统</a> <a href="/tags/%E6%B1%87%E7%BC%96/" style="font-size: 13px;">汇编</a> <a href="/tags/%E7%9F%AD%E7%AF%87%E5%B0%8F%E8%AF%B4/" style="font-size: 13px;">短篇小说</a> <a href="/tags/%E7%AE%97%E6%B3%95%E9%A2%98/" style="font-size: 14px;">算法题</a> <a href="/tags/%E8%87%AA%E7%94%B1/" style="font-size: 13px;">自由</a>
    </div>
  </div>

    
      
  <div class="widget">
    <h3 class="widget-title">归档</h3>
    <div class="widget-body">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/12/">十二月 2021</a><span class="archive-list-count">5</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/11/">十一月 2021</a><span class="archive-list-count">28</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/08/">八月 2021</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/07/">七月 2021</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/04/">四月 2021</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/01/">一月 2020</a><span class="archive-list-count">2</span></li></ul>
    </div>
  </div>


    
      
  <div class="widget">
    <h3 class="widget-title">最新文章</h3>
    <div class="widget-body">
      <ul class="recent-post-list list-unstyled no-thumbnail">
        
          <li>
            
            <div class="item-inner">
              <p class="item-category">
                <a class="category-link" href="/categories/Dailycode/">Dailycode</a>
              </p>
              <p class="item-title">
                <a href="/2021/12/04/20201204/" class="title">Dailycode</a>
              </p>
              <p class="item-date">
                <time datetime="2021-12-03T16:00:00.000Z" itemprop="datePublished">2021-12-04</time>
              </p>
            </div>
          </li>
          
          <li>
            
            <div class="item-inner">
              <p class="item-category">
                
              </p>
              <p class="item-title">
                <a href="/2021/12/02/%E5%9C%A8%EF%BC%8C%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%95%A5%E7%8E%A9%E6%84%8F%E5%84%BF%E5%95%8A/" class="title">在，机器学习啥玩意儿啊</a>
              </p>
              <p class="item-date">
                <time datetime="2021-12-02T01:30:35.845Z" itemprop="datePublished">2021-12-02</time>
              </p>
            </div>
          </li>
          
          <li>
            
            <div class="item-inner">
              <p class="item-category">
                <a class="category-link" href="/categories/Dailycode/">Dailycode</a>
              </p>
              <p class="item-title">
                <a href="/2021/12/02/20211202/" class="title">Dailycode</a>
              </p>
              <p class="item-date">
                <time datetime="2021-12-01T16:00:00.000Z" itemprop="datePublished">2021-12-02</time>
              </p>
            </div>
          </li>
          
          <li>
            
            <div class="item-inner">
              <p class="item-category">
                <a class="category-link" href="/categories/Dailycode/">Dailycode</a>
              </p>
              <p class="item-title">
                <a href="/2021/12/01/20211201/" class="title">Dailycode</a>
              </p>
              <p class="item-date">
                <time datetime="2021-11-30T16:00:00.000Z" itemprop="datePublished">2021-12-01</time>
              </p>
            </div>
          </li>
          
          <li>
            
            <div class="item-inner">
              <p class="item-category">
                <a class="category-link" href="/categories/%E4%B9%A6/">书</a>
              </p>
              <p class="item-title">
                <a href="/2021/12/01/%E9%BB%91%E7%BE%8A-%E5%8D%A1%E5%B0%94%E7%BB%B4%E8%AF%BA/" class="title">《黑羊》</a>
              </p>
              <p class="item-date">
                <time datetime="2021-11-30T16:00:00.000Z" itemprop="datePublished">2021-12-01</time>
              </p>
            </div>
          </li>
          
      </ul>
    </div>
  </div>
  

    
  </div>
</aside>

  
  
<main class="main" role="main">
  <div class="content">
  <article id="post-在，机器学习啥玩意儿啊" class="article article-type-post" itemscope itemtype="http://schema.org/BlogPosting">
    
    <div class="article-header">
      
        
  
    <h1 class="article-title" itemprop="name">
      在，机器学习啥玩意儿啊
    </h1>
  

      
      <div class="article-meta">
        <span class="article-date">
    <i class="icon icon-calendar-check"></i>
	<a href="/2021/12/02/%E5%9C%A8%EF%BC%8C%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%95%A5%E7%8E%A9%E6%84%8F%E5%84%BF%E5%95%8A/" class="article-date">
	  <time datetime="2021-12-02T01:30:35.845Z" itemprop="datePublished">2021-12-02</time>
	</a>
</span>
        
        

        

        <span class="post-comment"><i class="icon icon-comment"></i> <a href="/2021/12/02/%E5%9C%A8%EF%BC%8C%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%95%A5%E7%8E%A9%E6%84%8F%E5%84%BF%E5%95%8A/#comments" class="article-comment-link">评论</a></span>
        
	
		<span class="post-wordcount hidden-xs" itemprop="wordCount">字数统计: 3k(字)</span>
	
	
		<span class="post-readcount hidden-xs" itemprop="timeRequired">阅读时长: 12(分)</span>
	

      </div>
    </div>
    <div class="article-entry marked-body" itemprop="articleBody">
      
        <p>###深度学习（Deep Learning）<br>    1、基于卷积运算的神经网络系统，即卷积神经网络(CNN)。<br>    2、基于多层神经元的自编码神经网络，包括自编码( Auto encoder)以及近年来受到广泛关注的稀疏编码两类( Sparse Coding)。<br>    3、以多层自编码神经网络的方式进行预训练，进而结合鉴别信息进一步优化神经网络权值的深度置信网络(DBN)。</p>
<hr>
<p>好，所以这里我只关心CNN，因为要用了，看看CNN的历史<br><a href="https://zhuanlan.zhihu.com/p/76275427" target="_blank" rel="noopener">参考</a></p>
<p>####1. LeNet<br>论文: Gradient-based learning applied to document recognition], 发表时间：1998 年</p>
<blockquote>
<p>第一次定义了 CNN 网络结构。</p>
<p>定义了卷积神经网络（Convolutional Neural Network, CNN）的基本框架：卷积层 + 池化层（Pooling Layer） + 全连接层</p>
<p>定义了卷积层（Convolution Layer），与全连接层相比，卷积层的不同之处有两点：局部连接（引进“感受野”这一概念）、权值共享（减少参数数量）</p>
<p>利用池化层进行下采样（Downsampooling），从而减少计算量</p>
<p>用 Tanh 作为非线性激活函数（现在看到的都是改进过的 LeNet 了，用 ReLU 代替 Tanh。相较于 Sigmoid，Tanh 以原点对称（zero-centered），收敛速度会快。</p>
</blockquote>
<p>####2. AlexNet</p>
<p>论文：ImageNet Classification with Deep Convolutional Neural Networks, 发表时间：2012 年<br>特点：</p>
<blockquote>
<p>采用双 GPU 网络结构，从而可以设计出更“大”、更“深”的网络（相较于当时的算力来说）</p>
<p>采用 ReLU 代替 Tanh，稍微解决梯度消失问题（Gradient Vanishing Problem），加快网络收敛速度。（关于常见激活函数的比较，可以看这篇：常用激活函数的比较 - 徐小贱民的文章 - 知乎）<br>提出局部相应归一化（LRN, Local Response Normalization），据作者所言，该操作能减少指标 Top-1/Top-5 Error Rate 1.4%/1.2%。<br>令 Pooling 操作中的 stride 小于池化核的大小，从而使相邻的池化区域存在重叠部分，这一操作称为 Overlapping Pooling。据作者所言，这一操作能减少指标 Top-1/Top-5 Error Rate 0.4%/0.3%，并且减少过拟合现象。</p>
<p>对训练数据进行随机裁剪（Randm Crop），将训练图像由 256 × 256 裁剪为 224 × 224，并做随机的镜像翻转（Horizontal Reflection）。并在测试时，从图像的四个角以及中心进行裁剪，并进行镜像翻转，这样可以得到 10 个 Patch，将这些 Patch 的结果进行平均，从而得到最终预测结果。（之前在一个人脸识别比赛中，我师兄用这样的操作直接提高了４~5个点，算是一种简单的集成操作吧）<br>对训练图像做 PCA（主成分分析），利用服从 (0,0.1) 的高斯分布的随机变量对主成分进行扰动。作者指出，这一操作能减少指标 Top-1 Error Rate 1%。</p>
<p>利用 Dropout 避免网络过拟合。（我觉得这也算是集成操作的一种，因为随着模型的复杂度的提高，弱分类器也会越来越大，纯粹由弱分类器进行 Ensemble 应该不实际。最近谷歌对 Dropout 的专利貌似申请下来了，据说相关文档详细到可以作为 Dropout 的使用指南。）</p>
</blockquote>
<p>####3. VGG<br>论文：Very Deep Convolutional Networks for Large-Scale Image Recognition, 发表时间：2014.09</p>
<p>特点：</p>
<blockquote>
<p>VGG 其实跟 AlexNet 有一定的相似之处，都是由五个卷积层与激活函数叠加的部分和三个全连接层组成，但是不同的是，VGG加“深”了前面由五个卷积层与激活函数叠加的部分，使得每部分并不是一个卷积层加一个激活函数组成，而是多个这样的组合组成一部分（有人习惯称这个为 Conv Layer Group），每个部分之间进行池化操作。</p>
<p>此外，VGG 与当时其他卷积神经网络不同，不采用感受野大的卷积核（如：7 × 7，5 × 5），反而采用感受野小的卷积核（3 × 3）。关于这样做的好处，作者指出有如下两点：减少网络参数量；由于参数量被大幅减小，于是可以用多个感受野小的卷积层替换掉之前一个感受野大的卷积层，从而增加网络的非线性表达能力。</p>
<p>从 VGG-16 开始，VGG 引进卷积核大小为 1 × 1 的卷积层（最早应该在 Network In Network 提到），使得在不影响特征图大小的情况下，增加网络的非线性表达能力。</p>
<p>由上图可以看出，VGG 每个“大”部分计算得到的特征图大小应该是固定的，以输入大小为 (224,244,3) 的图像举例，所计算得到的特征图大小分别为 (112,112,64)，(56,56,128)，(28,28,256)，(14,14,512)，(7,7,512)。（VGG 的最后三层全连接层太大了，尤其是第一层，大小达到了 (25088,4096) ）</p>
</blockquote>
<p>####4. Inception Net<br>Inception Net V1 (GoogLeNet)<br>论文链接：Going Deeper with Convolutions, 发表时间：2014.09</p>
<blockquote>
<p>作者在文中指出，提高模型表达能力的最直接的办法就是增加模型的“大小”，而这又会导致两个问题的产生：模型越大，其网络参数也就越大，就越容易产生过拟合现象，所以就需要更大的数据集，然而大型数据集的构建成本是很高昂的；模型越大，对于计算资源的需求就越大，这在现实任务中是难以接受的。而作者认为解决这两个问题的基本方法是将全连接层，甚至是卷积层改为稀疏的网络结构。（作者还在文中指出，GoogLeNet 的参数仅有 AlexNet 的 1/12，而 AlexNet 的全连接层的参数量甚至占到了自身参数量的 90% 以上）</p>
<blockquote>
</blockquote>
<p>受到 Network In Network 以及 HeHebbian Principle 的启发，作者通过增加网络的宽度，从而提高网络的表达能力，并尝试找到卷积神经网络中的最优局部稀疏结构，即 Inception Module（如上图所示）。</p>
<p>作者所设计的 Inception Module 与常见的网络结构不同，打破了常规的卷积层串联的设计思路，选择将卷积核大小为 1 × 1，3 × 3，5 × 5 的卷积层和池化核大小为 3 × 3 的池化层进行并联，并将各自所得到的特征图进行 Concatenate 操作合并在一起，作为后续的输入。</p>
</blockquote>
<p>####5. ResNet<br>Residual Network<br>论文链接：Deep Residual Learning for Image Recognition，发表时间：2015.12</p>
<p>网络结构：</p>
<blockquote>
<p>简单来说，Kaiming 在文中提出了残差结构（Residual Block，如上图左侧所示），使得原本所要拟合的函数 [公式] ，改为 [公式] ，其中， [公式] 。虽然在“多个非线性层可以拟合任意函数”这一假设下二者并无区别，但是 Kaiming 假设模型学习后者，将更容易进行优化与收敛。（在残差结构中，模型利用 Shortcut 进行 Identity Mapping，这样也解决了梯度消失现象）</p>
<p>由于 Residual Block 并不需要额外的参数以及计算量，Kaiming 在文中以此做了多组对照实验，证明该网络结构的有效性（所用的两个 ResNet 为 ResNet-18 和 ResNet-34）。但是，若要将模型的深度继续不断增加，需要对其进行改进：将原先的 Residual Block（上图右侧所示，也被称作 Basic Block） 改进为 Bottleneck Block，减少模型的参数与计算量。</p>
</blockquote>
<p>####6. DenseNet<br>论文链接：Densely Connected Convolutional Networks，发表时间：2016.08</p>
<p>模型的参数指的是啥，计算量指的是啥，数据增强增了个啥，<br>卷积层（Convolutional layer）<br>线性整流层（Rectified Linear Units layer, ReLU layer）<br>池化层（Pooling layer）<br>全连接层（ Fully-Connected layer）    </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><span class="line">from torch import nn</span><br><span class="line">import torch as t</span><br><span class="line">from torch.nn import functional as F</span><br><span class="line"></span><br><span class="line">class ResidualBlock(nn.Module):</span><br><span class="line">    #实现子module: Residual    Block</span><br><span class="line">    def __init__(self,inchannel,outchannel,stride&#x3D;1,shortcut&#x3D;None):</span><br><span class="line">        super(ResidualBlock,self).__init__()</span><br><span class="line">        self.left&#x3D;nn.Sequential(</span><br><span class="line">            nn.Conv2d(inchannel,outchannel,3,stride,1,bias&#x3D;False),</span><br><span class="line">            nn.BatchNorm2d(outchannel),</span><br><span class="line">            nn.ReLU(inplace&#x3D;True),</span><br><span class="line">            nn.Conv2d(outchannel,outchannel,3,1,1,bias&#x3D;False),</span><br><span class="line">            nn.BatchNorm2d(outchannel)</span><br><span class="line">        )</span><br><span class="line">        </span><br><span class="line">        self.right&#x3D;shortcut</span><br><span class="line">        </span><br><span class="line">    def forward(self,x):</span><br><span class="line">        out&#x3D;self.left(x)</span><br><span class="line">        residual&#x3D;x if self.right is None else self.right(x)</span><br><span class="line">        out+&#x3D;residual</span><br><span class="line">        return F.relu(out)</span><br><span class="line">class ResNet(nn.Module):</span><br><span class="line">    #实现主module:ResNet34</span><br><span class="line">    #ResNet34包含多个layer,每个layer又包含多个residual block</span><br><span class="line">    #用子module实现residual block , 用 _make_layer 函数实现layer</span><br><span class="line">    def __init__(self,num_classes&#x3D;1000):</span><br><span class="line">        super(ResNet,self).__init__()</span><br><span class="line">        self.pre&#x3D;nn.Sequential(#一个有序的容器，神经网络模块将按照在传入构造器的顺序依次被添加到计算图中执行，同时以神经网络模块为元素的有序字典也可以作为传入参数。</span><br><span class="line">            nn.Conv2d(3,64,7,2,3,bias&#x3D;False),</span><br><span class="line">            nn.BatchNorm2d(64),</span><br><span class="line">            nn.ReLU(inplace&#x3D;True),</span><br><span class="line">            nn.MaxPool2d(3,2,1)</span><br><span class="line">        )</span><br><span class="line">        #重复的layer,分别有3,4,6,3个residual block</span><br><span class="line">        self.layer1&#x3D;self._make_layer(64,64,3)</span><br><span class="line">        self.layer2&#x3D;self._make_layer(64,128,4,stride&#x3D;2)</span><br><span class="line">        self.layer3&#x3D;self._make_layer(128,256,6,stride&#x3D;2)</span><br><span class="line">        self.layer4&#x3D;self._make_layer(256,512,3,stride&#x3D;2)</span><br><span class="line">#</span><br><span class="line">        #分类用的全连接</span><br><span class="line">        self.fc&#x3D;nn.Linear(512,num_classes)</span><br><span class="line">#    </span><br><span class="line">    def _make_layer(self,inchannel,outchannel,block_num,stride&#x3D;1):</span><br><span class="line">        #构建layer,包含多个residual block</span><br><span class="line">        shortcut&#x3D;nn.Sequential(</span><br><span class="line">            nn.Conv2d(inchannel,outchannel,1,stride,bias&#x3D;False),</span><br><span class="line">            nn.BatchNorm2d(outchannel))</span><br><span class="line">#</span><br><span class="line">        layers&#x3D;[ ]</span><br><span class="line">        layers.append(ResidualBlock(inchannel,outchannel,stride,shortcut))</span><br><span class="line">#</span><br><span class="line">        for i in range(1,block_num):</span><br><span class="line">            layers.append(ResidualBlock(outchannel,outchannel))</span><br><span class="line">        return nn.Sequential(*layers)</span><br><span class="line">#</span><br><span class="line">    def forward(self,x):</span><br><span class="line">        x&#x3D;self.pre(x)</span><br><span class="line">#</span><br><span class="line">        x&#x3D;self.layer1(x)</span><br><span class="line">        x&#x3D;self.layer2(x)</span><br><span class="line">        x&#x3D;self.layer3(x)</span><br><span class="line">        x&#x3D;self.layer4(x)</span><br><span class="line">#</span><br><span class="line">        x&#x3D;F.avg_pool2d(x,7)</span><br><span class="line">        x&#x3D;x.view(x.size(0),-1)</span><br><span class="line">        return self.fc(x)</span><br></pre></td></tr></table></figure>

<hr>
<p>import torch.nn as nn<br>import torch<br>from torch.nn import functional as F</p>
<p>class ResidualBlock(nn.Module):<br>    #实现子module：Residual Block<br>    def <strong>init</strong>(self, in_ch, out_ch, stride=1, shortcut=None):<br>        super(ResidualBlock,self).<strong>init</strong>()<br>        self.left = nn.Sequential(<br>            nn.Conv2d(in_ch,out_ch,3,stride,padding=1,bias=False),<br>            nn.BatchNorm2d(out_ch),<br>            nn.ReLU(inplace = True),#inplace = True原地操作<br>            nn.Conv2d(out_ch,out_ch,3,stride=1,padding=1,bias=False),<br>            nn.BatchNorm2d(out_ch)<br>            )<br>        self.right = shortcut</p>
<pre><code>def forward(self,x):
    out = self.left(x)
    residual = x if self.right is None else self.right(x)
    out += residual
    return F.relu(out)</code></pre><p>class ResNet34(nn.Module):#224x224x3<br>    #实现主module:ResNet34<br>    def <strong>init</strong>(self, num_classes=1):<br>        super(ResNet34,self).<strong>init</strong>()<br>        self.pre = nn.Sequential(<br>                nn.Conv2d(3,64,7,stride=2,padding=3,bias=False),# (224+2*p-)/2(向下取整)+1，size减半-&gt;112<br>                nn.BatchNorm2d(64),#112x112x64<br>                nn.ReLU(inplace = True),<br>                nn.MaxPool2d(3,2,1)#kernel_size=3, stride=2, padding=1<br>                )#56x56x64</p>
<pre><code>    #重复的layer,分别有3,4,6,3个residual block
    self.layer1 = self.make_layer(64,64,3)#56x56x64,layer1层输入输出一样，make_layer里，应该不用对shortcut进行处理，但是为了统一操作。。。
    self.layer2 = self.make_layer(64,128,4,stride=2)#第一个stride=2,剩下3个stride=1;#28x28x128
    self.layer3 = self.make_layer(128,256,6,stride=2)#14x14x256
    self.layer4 = self.make_layer(256,512,3,stride=2)#7x7x512
    #分类用的全连接
    self.fc = nn.Linear(512,num_classes)

def make_layer(self,in_ch,out_ch,block_num,stride=1):
    #当维度增加时，对shortcut进行option B的处理
    shortcut = nn.Sequential(#首个ResidualBlock需要进行option B处理
            nn.Conv2d(in_ch,out_ch,1,stride,bias=False),#1x1卷积用于增加维度；stride=2用于减半size；为简化不考虑偏差
            nn.BatchNorm2d(out_ch)
            )
    layers = []
    layers.append(ResidualBlock(in_ch,out_ch,stride,shortcut))

    for i in range(1,block_num):
        layers.append(ResidualBlock(out_ch,out_ch))#后面的几个ResidualBlock,shortcut直接相加
    return nn.Sequential(*layers)

def forward(self,x):    #224x224x3
    x = self.pre(x)     #56x56x64
    x = self.layer1(x)  #56x56x64
    x = self.layer2(x)  #28x28x128
    x = self.layer3(x)  #14x14x256
    x = self.layer4(x)  #7x7x512
    x = F.avg_pool2d(x,7)#1x1x512
    x = x.view(x.size(0),-1)#将输出拉伸为一行：1x512
    x = self.fc(x)    #1x1
    # nn.BCELoss:二分类用的交叉熵，用的时候需要在该层前面加上 Sigmoid 函数
    return nn.Sigmoid()(x)#1x1，将结果化为(0~1)之间</code></pre><p>—<br>版权声明：本文为CSDN博主「Ginkgo__」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。<br>原文链接：<a href="https://blog.csdn.net/weixin_42135399/article/details/90371489" target="_blank" rel="noopener">https://blog.csdn.net/weixin_42135399/article/details/90371489</a></p>
<hr>
<p><a href="https://blog.csdn.net/qq_34447388/article/details/79503643" target="_blank" rel="noopener">原文链接</a></p>
<p>####为什么自己写多层神经网络模块只需要实现<strong>init</strong>和forward<br><a href="https://blog.csdn.net/dss_dssssd/article/details/82977170" target="_blank" rel="noopener">链接</a></p>
<p>nn linear的源码<a href="https://pytorch.org/docs/stable/_modules/torch/nn/modules/linear.html" target="_blank" rel="noopener">链接</a></p>
<p>module的源码<a href="https://github.com/pytorch/pytorch/blob/master/torch/nn/modules/module.py" target="_blank" rel="noopener">链接</a></p>
<p>全连接神经网络和卷积神经网络<a href="https://zhuanlan.zhihu.com/p/47184529" target="_blank" rel="noopener">传送门</a></p>

      
    </div>
    <div class="article-footer">
      <blockquote class="mt-2x">
  <ul class="post-copyright list-unstyled">
    
    <li class="post-copyright-link hidden-xs">
      <strong>本文链接：</strong>
      <a href="http://spcablast.club/2021/12/02/%E5%9C%A8%EF%BC%8C%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%95%A5%E7%8E%A9%E6%84%8F%E5%84%BF%E5%95%8A/" title="在，机器学习啥玩意儿啊" target="_blank" rel="external">http://spcablast.club/2021/12/02/%E5%9C%A8%EF%BC%8C%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%95%A5%E7%8E%A9%E6%84%8F%E5%84%BF%E5%95%8A/</a>
    </li>
    
    <li class="post-copyright-license">
      <strong>版权声明： </strong> 本博客所有文章除特别声明外，均采用 <a href="http://creativecommons.org/licenses/by/4.0/deed.zh" target="_blank" rel="external">CC BY 4.0 CN协议</a> 许可协议。转载请注明出处！
    </li>
  </ul>
</blockquote>


<div class="panel panel-default panel-badger">
  <div class="panel-body">
    <figure class="media">
      <div class="media-left">
        <a href="https://github.com/Spcabalst" target="_blank" class="img-burn thumb-sm visible-lg">
          <img src="/images/avatar.jpg" class="img-rounded w-full" alt="">
        </a>
      </div>
      <div class="media-body">
        <h3 class="media-heading"><a href="https://github.com/Spcabalst" target="_blank"><span class="text-dark">SPCA</span><small class="ml-1x">Human</small></a></h3>
        <div>know yourself!</div>
      </div>
    </figure>
  </div>
</div>


    </div>
  </article>
  
    
  <section id="comments">
  	
      <div id="vcomments"></div>
    
  </section>


  
</div>

  <nav class="bar bar-footer clearfix" data-stick-bottom>
  <div class="bar-inner">
  
  <ul class="pager pull-left">
    
    <li class="prev">
      <a href="/2021/12/04/20201204/" title="Dailycode"><i class="icon icon-angle-left" aria-hidden="true"></i><span>&nbsp;&nbsp;上一篇</span></a>
    </li>
    
    
    <li class="next">
      <a href="/2021/12/02/20211202/" title="Dailycode"><span>下一篇&nbsp;&nbsp;</span><i class="icon icon-angle-right" aria-hidden="true"></i></a>
    </li>
    
    
  </ul>
  
  
  <!-- Button trigger modal -->
  <button type="button" class="btn btn-fancy btn-donate pop-onhover bg-gradient-warning" data-toggle="modal" data-target="#donateModal"><span>赏</span></button>
  <!-- <div class="wave-icon wave-icon-danger btn-donate" data-toggle="modal" data-target="#donateModal">
    <div class="wave-circle"><span class="icon"><i class="icon icon-bill"></i></span></div>
  </div> -->
  
  
  <div class="bar-right">
    
    <div class="share-component" data-sites="weibo,qq,wechat,facebook,twitter" data-mobile-sites="weibo,qq,qzone"></div>
    
  </div>
  </div>
</nav>
  
<!-- Modal -->
<div class="modal modal-center modal-small modal-xs-full fade" id="donateModal" tabindex="-1" role="dialog">
  <div class="modal-dialog" role="document">
    <div class="modal-content donate">
      <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button>
      <div class="modal-body">
        <div class="donate-box">
          <div class="donate-head">
            <p>感谢您的支持，我会继续努力的!</p>
          </div>
          <div class="tab-content">
            <div role="tabpanel" class="tab-pane fade active in" id="alipay">
              <div class="donate-payimg">
                <img src="/images/donate/alipayimg.png" alt="扫码支持" title="扫一扫" />
              </div>
              <p class="text-muted mv">扫码打赏，你说多少就多少</p>
              <p class="text-grey">打开支付宝扫一扫，即可进行扫码打赏哦</p>
            </div>
            <div role="tabpanel" class="tab-pane fade" id="wechatpay">
              <div class="donate-payimg">
                <img src="/images/donate/wechatpayimg.png" alt="扫码支持" title="扫一扫" />
              </div>
              <p class="text-muted mv">扫码打赏，你说多少就多少</p>
              <p class="text-grey">打开微信扫一扫，即可进行扫码打赏哦</p>
            </div>
          </div>
          <div class="donate-footer">
            <ul class="nav nav-tabs nav-justified" role="tablist">
              <li role="presentation" class="active">
                <a href="#alipay" id="alipay-tab" role="tab" data-toggle="tab" aria-controls="alipay" aria-expanded="true"><i class="icon icon-alipay"></i> 支付宝</a>
              </li>
              <li role="presentation" class="">
                <a href="#wechatpay" role="tab" id="wechatpay-tab" data-toggle="tab" aria-controls="wechatpay" aria-expanded="false"><i class="icon icon-wepay"></i> 微信支付</a>
              </li>
            </ul>
          </div>
        </div>
      </div>
    </div>
  </div>
</div>



</main>

  <footer class="footer" itemscope itemtype="http://schema.org/WPFooter">
	
	
    <ul class="social-links">
    	
        <li><a href="https://github.com/Spcabalst" target="_blank" title="Github" data-toggle=tooltip data-placement=top><i class="icon icon-github"></i></a></li>
        
        <li><a href="/null" target="_blank" title="Weibo" data-toggle=tooltip data-placement=top><i class="icon icon-weibo"></i></a></li>
        
        <li><a href="/null" target="_blank" title="Rss" data-toggle=tooltip data-placement=top><i class="icon icon-rss"></i></a></li>
        
    </ul>

    <div class="copyright">
    	
        <div class="publishby">
        	Theme by <a href="https://github.com/cofess" target="_blank"> cofess </a>base on <a href="https://github.com/cofess/hexo-theme-pure" target="_blank">pure</a>.
        </div>
    </div>
</footer>
  <script src="//cdn.jsdelivr.net/npm/jquery@1.12.4/dist/jquery.min.js"></script>
<script>
window.jQuery || document.write('<script src="js/jquery.min.js"><\/script>')
</script>

<script src="/js/plugin.min.js"></script>


<script src="/js/application.js"></script>


    <script>
(function (window) {
    var INSIGHT_CONFIG = {
        TRANSLATION: {
            POSTS: '文章',
            PAGES: '页面',
            CATEGORIES: '分类',
            TAGS: '标签',
            UNTITLED: '(未命名)',
        },
        ROOT_URL: '/',
        CONTENT_URL: '/content.json',
    };
    window.INSIGHT_CONFIG = INSIGHT_CONFIG;
})(window);
</script>

<script src="/js/insight.js"></script>






   




   
    
  <script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/valine"></script>
  <script type="text/javascript">
  var GUEST = ['nick', 'mail', 'link'];
  var meta = 'nick,mail,link';
  meta = meta.split(',').filter(function(item) {
    return GUEST.indexOf(item) > -1;
  });
  new Valine({
    el: '#vcomments',
    verify: false,
    notify: false,
    appId: 'hsaJ5cJR7JeNndFXLpUut3Bj-gzGzoHsz',
    appKey: 'VQQFVxzpopnD2jyMtgWLgwWL',
    placeholder: 'Say you wanna dance',
    avatar: 'mm',
    meta: meta,
    pageSize: '10' || 10,
    visitor: false
  });
  </script>
     







</body>
</html>